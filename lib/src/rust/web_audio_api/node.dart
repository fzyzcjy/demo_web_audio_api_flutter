// This file is automatically generated, so please do not edit it.
// Generated by `flutter_rust_bridge`@ 2.0.0-dev.37.

// ignore_for_file: invalid_use_of_internal_member, unused_import, unnecessary_import

import '../frb_generated.dart';
import '../web_audio_api.dart';
import 'context.dart';
import 'media_streams.dart';
import 'package:flutter_rust_bridge/flutter_rust_bridge_for_generated.dart';

// These functions are ignored because they are not marked as `pub`: `apply_curve`, `apply_mono_to_stereo_gain`, `apply_stereo_to_stereo_gain`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_receiver_is_total_eq`, `assert_valid_channel_count_mode`, `assert_valid_channel_count_mode`, `assert_valid_channel_count_mode`, `assert_valid_channel_count_mode`, `assert_valid_channel_count_mode`, `assert_valid_channel_count`, `assert_valid_channel_count`, `assert_valid_channel_count`, `assert_valid_channel_count`, `assert_valid_channel_count`, `assert_valid_channel_interpretation`, `assert_valid_cone_outer_gain`, `assert_valid_feedback_coefs`, `assert_valid_feedforward_coefs`, `assert_valid_number_of_channels`, `assert_valid_number_of_channels`, `before_drop`, `before_drop`, `before_drop`, `calculate_coefs`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `channel_config`, `check_ring_buffer_up_down_mix`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `complex`, `cone_gain`, `connect_from_output_to_input`, `count_mode`, `count`, `db_to_lin`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `default`, `disconnect_dest_from_output_to_input`, `disconnect_dest_from_output`, `disconnect_dest`, `disconnect_output`, `disconnect`, `dist_gain`, `downsample_x2`, `downsample_x4`, `drop`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `eq`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `from_raw_parts`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `from`, `generate_custom`, `generate_sample`, `generate_sawtooth`, `generate_sine`, `generate_square`, `generate_triangle`, `get_computed_freq`, `get_phase_incr`, `get_playback_infos`, `get_stereo_gains`, `handle_control_message`, `has_side_effects`, `has_side_effects`, `inner`, `interpretation`, `into_channel_config`, `inverse`, `lin_to_db`, `load_hrtf_processor`, `new`, `new`, `new`, `new`, `new`, `new`, `new`, `new`, `new`, `next`, `normalize_buffer`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_inputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `number_of_outputs`, `onmessage`, `onmessage`, `onmessage`, `onmessage`, `onmessage`, `onmessage`, `onmessage`, `onmessage`, `poly_blep`, `precomputed_sine_table`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `process`, `real`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `registration`, `ring_buffer_mut`, `ring_buffer_mut`, `roll_zero`, `samples_out_mut`, `samples_out`, `set_channel_count_mode`, `set_channel_count_mode`, `set_channel_count_mode`, `set_channel_count_mode`, `set_channel_count_mode`, `set_channel_count_mode`, `set_channel_count_mode`, `set_channel_count`, `set_channel_count`, `set_channel_count`, `set_channel_count`, `set_channel_count`, `set_channel_count`, `set_channel_count`, `set_channel_interpretation`, `set_count_mode`, `set_count`, `set_interpretation`, `start_at`, `start_at`, `start_at`, `start`, `start`, `start`, `stop_at`, `stop_at`, `stop_at`, `stop`, `stop`, `stop`, `tail_time_samples`, `tail`, `unroll_phase`, `upsample_x2`, `upsample_x4`
// These types are ignored because they are not used by any `pub` functions: `AnalyserRenderer`, `AudioBufferRendererState`, `AudioBufferSourceRenderer`, `AudioDestinationNodeStream`, `BiquadFilterRenderer`, `ChannelConfigInner`, `ChannelConfig`, `ChannelMergerRenderer`, `ChannelSplitterRenderer`, `Coefficients`, `ConstantSourceRenderer`, `ControlMessage`, `ConvolverRendererInner`, `ConvolverRenderer`, `DelayReader`, `DelayWriter`, `DestinationRenderer`, `DynamicsCompressorRenderer`, `Fft`, `GainRenderer`, `HrtfState`, `IirFilterRenderer`, `LoopState`, `MediaStreamRenderer`, `OscillatorRenderer`, `PannerRenderer`, `PlaybackInfo`, `RendererConfig`, `ResamplerConfig`, `Resampler`, `Schedule`, `ScriptProcessorRenderer`, `SpatialParams`, `StereoPannerRenderer`, `WaveShaperRenderer`

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AnalyserNode>>
@sealed
class AnalyserNode extends RustOpaque {
  // Not to be used by end users
  AnalyserNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AnalyserNode.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_AnalyserNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_AnalyserNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_AnalyserNodePtr,
  );

  /// The size of the FFT used for frequency-domain analysis (in sample-frames)
  ///
  /// # Panics
  ///
  /// This method may panic if the lock to the inner analyser is poisoned
  Future<BigInt> fftSize() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeFftSize(
        that: this,
      );

  /// Number of bins in the FFT results, is half the FFT size
  ///
  /// # Panics
  ///
  /// This method may panic if the lock to the inner analyser is poisoned
  Future<BigInt> frequencyBinCount() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeFrequencyBinCount(
        that: this,
      );

  /// Copy the current frequency data scaled between min_decibels and
  /// max_decibels into the provided buffer
  ///
  /// # Panics
  ///
  /// This method may panic if the lock to the inner analyser is poisoned
  Future<void> getByteFrequencyData({required U8 buffer}) =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeGetByteFrequencyData(
          that: this, buffer: buffer);

  /// Copy the current time domain data as u8 values into the provided buffer
  ///
  /// # Panics
  ///
  /// This method may panic if the lock to the inner analyser is poisoned
  Future<void> getByteTimeDomainData({required U8 buffer}) =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeGetByteTimeDomainData(
          that: this, buffer: buffer);

  /// Copy the current frequency data into the provided buffer
  ///
  /// # Panics
  ///
  /// This method may panic if the lock to the inner analyser is poisoned
  Future<void> getFloatFrequencyData({required F32 buffer}) =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeGetFloatFrequencyData(
          that: this, buffer: buffer);

  /// Copy the current time domain data as f32 values into the provided buffer
  ///
  /// # Panics
  ///
  /// This method may panic if the lock to the inner analyser is poisoned
  Future<void> getFloatTimeDomainData({required F32 buffer}) =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeGetFloatTimeDomainData(
          that: this, buffer: buffer);

  /// Maximum power value in the scaling range for the FFT analysis data for
  /// conversion to unsigned byte values. The default value is -30.
  ///
  /// # Panics
  ///
  /// This method may panic if the lock to the inner analyser is poisoned
  Future<double> maxDecibels() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeMaxDecibels(
        that: this,
      );

  /// Minimum power value in the scaling range for the FFT analysis data for
  /// conversion to unsigned byte values. The default value is -100.
  ///
  /// # Panics
  ///
  /// This method may panic if the lock to the inner analyser is poisoned
  Future<double> minDecibels() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeMinDecibels(
        that: this,
      );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  static Future<AnalyserNode> newInstance(
          {required C context, required AnalyserOptions options}) =>
      RustLib.instance.api
          .webAudioApiNodeAnalyserNodeNew(context: context, options: options);

  /// Set FFT size
  ///
  /// # Panics
  ///
  /// This function panics if fft_size is not a power of two or not in the range [32, 32768]
  Future<void> setFftSize({required BigInt fftSize}) => RustLib.instance.api
      .webAudioApiNodeAnalyserNodeSetFftSize(that: this, fftSize: fftSize);

  /// Set max decibels
  ///
  /// # Panics
  ///
  /// This function panics if the value is set to a value less than or equal
  /// to min decibels.
  Future<void> setMaxDecibels({required double value}) => RustLib.instance.api
      .webAudioApiNodeAnalyserNodeSetMaxDecibels(that: this, value: value);

  /// Set min decibels
  ///
  /// # Panics
  ///
  /// This function panics if the value is set to a value more than or equal
  /// to max decibels.
  Future<void> setMinDecibels({required double value}) => RustLib.instance.api
      .webAudioApiNodeAnalyserNodeSetMinDecibels(that: this, value: value);

  /// Set smoothing time constant
  ///
  /// # Panics
  ///
  /// This function panics if the value is set to a value less than 0 or more than 1.
  Future<void> setSmoothingTimeConstant({required double value}) =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeSetSmoothingTimeConstant(
          that: this, value: value);

  /// Time averaging parameter with the last analysis frame.
  /// A value from 0 -> 1 where 0 represents no time averaging with the last
  /// analysis frame. The default value is 0.8.
  ///
  /// # Panics
  ///
  /// This method may panic if the lock to the inner analyser is poisoned
  Future<double> smoothingTimeConstant() =>
      RustLib.instance.api.webAudioApiNodeAnalyserNodeSmoothingTimeConstant(
        that: this,
      );
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioBufferSourceNode>>
@sealed
class AudioBufferSourceNode extends RustOpaque {
  // Not to be used by end users
  AudioBufferSourceNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AudioBufferSourceNode.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_AudioBufferSourceNode,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioBufferSourceNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioBufferSourceNodePtr,
  );

  /// Current buffer value (nullable)
  Future<AudioBuffer?> buffer() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeBuffer(
        that: this,
      );

  /// K-rate [`AudioParam`] that defines a pitch transposition of the file,
  /// expressed in cents
  ///
  /// see <https://en.wikipedia.org/wiki/Cent_(music)>
  Future<AudioParam> detune() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeDetune(
        that: this,
      );

  /// Defines if the playback the [`AudioBuffer`] should be looped
  Future<bool> loop() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeLoop(
        that: this,
      );

  /// Defines the loop end point, in the time reference of the [`AudioBuffer`]
  Future<double> loopEnd() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeLoopEnd(
        that: this,
      );

  /// Defines the loop start point, in the time reference of the [`AudioBuffer`]
  Future<double> loopStart() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeLoopStart(
        that: this,
      );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  /// Create a new [`AudioBufferSourceNode`] instance
  static Future<AudioBufferSourceNode> newInstance(
          {required C context, required AudioBufferSourceOptions options}) =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeNew(
          context: context, options: options);

  /// K-rate [`AudioParam`] that defines the speed at which the [`AudioBuffer`]
  /// will be played, e.g.:
  /// - `0.5` will play the file at half speed
  /// - `-1` will play the file in reverse
  ///
  /// Note that playback rate will also alter the pitch of the [`AudioBuffer`]
  Future<AudioParam> playbackRate() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodePlaybackRate(
        that: this,
      );

  /// Current playhead position in seconds within the [`AudioBuffer`].
  ///
  /// This value is updated at the end of each render quantum.
  ///
  /// Unofficial v2 API extension, not part of the spec yet.
  /// See also: <https://github.com/WebAudio/web-audio-api/issues/2397#issuecomment-709478405>
  Future<double> position() =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodePosition(
        that: this,
      );

  /// Provide an [`AudioBuffer`] as the source of data to be played bask
  ///
  /// # Panics
  ///
  /// Panics if a buffer has already been given to the source (though `new` or through
  /// `set_buffer`)
  Future<void> setBuffer({required AudioBuffer audioBuffer}) =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeSetBuffer(
          that: this, audioBuffer: audioBuffer);

  Future<void> setLoop({required bool value}) => RustLib.instance.api
      .webAudioApiNodeAudioBufferSourceNodeSetLoop(that: this, value: value);

  Future<void> setLoopEnd({required double value}) => RustLib.instance.api
      .webAudioApiNodeAudioBufferSourceNodeSetLoopEnd(that: this, value: value);

  Future<void> setLoopStart({required double value}) =>
      RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeSetLoopStart(
          that: this, value: value);

  /// Start the playback at the given time and with a given offset
  ///
  /// # Panics
  ///
  /// Panics if the source was already started
  Future<void> startAtWithOffset(
          {required double start, required double offset}) =>
      RustLib.instance.api
          .webAudioApiNodeAudioBufferSourceNodeStartAtWithOffset(
              that: this, start: start, offset: offset);

  /// Start the playback at the given time, with a given offset, for a given duration
  ///
  /// # Panics
  ///
  /// Panics if the source was already started
  Future<void> startAtWithOffsetAndDuration(
          {required double start,
          required double offset,
          required double duration}) =>
      RustLib.instance.api
          .webAudioApiNodeAudioBufferSourceNodeStartAtWithOffsetAndDuration(
              that: this, start: start, offset: offset, duration: duration);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioDestinationNode>>
@sealed
class AudioDestinationNode extends RustOpaque {
  // Not to be used by end users
  AudioDestinationNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  AudioDestinationNode.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_AudioDestinationNode,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioDestinationNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_AudioDestinationNodePtr,
  );

  /// The maximum number of channels that the channelCount attribute can be set to (the max
  /// number of channels that the hardware is capable of supporting).
  /// <https://www.w3.org/TR/webaudio/#dom-audiodestinationnode-maxchannelcount>
  Future<BigInt> maxChannelCount() =>
      RustLib.instance.api.webAudioApiNodeAudioDestinationNodeMaxChannelCount(
        that: this,
      );
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<BiquadFilterNode>>
@sealed
class BiquadFilterNode extends RustOpaque {
  // Not to be used by end users
  BiquadFilterNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  BiquadFilterNode.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_BiquadFilterNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_BiquadFilterNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_BiquadFilterNodePtr,
  );

  /// Returns the detune audio parameter
  Future<AudioParam> detune() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeDetune(
        that: this,
      );

  /// Returns the frequency audio parameter
  Future<AudioParam> frequency() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeFrequency(
        that: this,
      );

  /// Returns the gain audio parameter
  Future<AudioParam> gain() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeGain(
        that: this,
      );

  /// Returns the frequency response for the specified frequencies
  ///
  /// # Arguments
  ///
  /// * `frequency_hz` - frequencies for which frequency response of the filter should be calculated
  /// * `mag_response` - magnitude of the frequency response of the filter
  /// * `phase_response` - phase of the frequency response of the filter
  ///
  /// # Panics
  ///
  /// This function will panic if arguments' lengths don't match
  ///
  Future<void> getFrequencyResponse(
          {required F32 frequencyHz,
          required F32 magResponse,
          required F32 phaseResponse}) =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeGetFrequencyResponse(
          that: this,
          frequencyHz: frequencyHz,
          magResponse: magResponse,
          phaseResponse: phaseResponse);

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  /// returns a `BiquadFilterNode` instance
  ///
  /// # Arguments
  ///
  /// * `context` - audio context in which the audio node will live.
  /// * `options` - biquad filter options
  static Future<BiquadFilterNode> newInstance(
          {required C context, required BiquadFilterOptions options}) =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeNew(
          context: context, options: options);

  /// Returns the Q audio parameter
  Future<AudioParam> q() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeQ(
        that: this,
      );

  /// biquad filter type setter
  ///
  /// # Arguments
  ///
  /// * `type_` - the biquad filter type (lowpass, highpass,...)
  Future<void> setType({required BiquadFilterType type}) => RustLib.instance.api
      .webAudioApiNodeBiquadFilterNodeSetType(that: this, type: type);

  /// Returns the biquad filter type
  Future<BiquadFilterType> type() =>
      RustLib.instance.api.webAudioApiNodeBiquadFilterNodeType(
        that: this,
      );
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<ChannelMergerNode>>
@sealed
class ChannelMergerNode extends RustOpaque {
  // Not to be used by end users
  ChannelMergerNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  ChannelMergerNode.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_ChannelMergerNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_ChannelMergerNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_ChannelMergerNodePtr,
  );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  static Future<ChannelMergerNode> newInstance(
          {required C context, required ChannelMergerOptions options}) =>
      RustLib.instance.api.webAudioApiNodeChannelMergerNodeNew(
          context: context, options: options);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<ChannelSplitterNode>>
@sealed
class ChannelSplitterNode extends RustOpaque {
  // Not to be used by end users
  ChannelSplitterNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  ChannelSplitterNode.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_ChannelSplitterNode,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_ChannelSplitterNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_ChannelSplitterNodePtr,
  );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  static Future<ChannelSplitterNode> newInstance(
          {required C context, required ChannelSplitterOptions options}) =>
      RustLib.instance.api.webAudioApiNodeChannelSplitterNodeNew(
          context: context, options: options);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<ConstantSourceNode>>
@sealed
class ConstantSourceNode extends RustOpaque {
  // Not to be used by end users
  ConstantSourceNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  ConstantSourceNode.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_ConstantSourceNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_ConstantSourceNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_ConstantSourceNodePtr,
  );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  static Future<ConstantSourceNode> newInstance(
          {required C context, required ConstantSourceOptions options}) =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeNew(
          context: context, options: options);

  Future<AudioParam> offset() =>
      RustLib.instance.api.webAudioApiNodeConstantSourceNodeOffset(
        that: this,
      );
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<ConvolverNode>>
@sealed
class ConvolverNode extends RustOpaque {
  // Not to be used by end users
  ConvolverNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  ConvolverNode.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_ConvolverNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_ConvolverNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_ConvolverNodePtr,
  );

  /// Get the current impulse response buffer
  Future<AudioBuffer?> buffer() =>
      RustLib.instance.api.webAudioApiNodeConvolverNodeBuffer(
        that: this,
      );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  /// returns a `ConvolverNode` instance
  ///
  /// # Arguments
  ///
  /// * `context` - audio context in which the audio node will live.
  /// * `options` - convolver options
  ///
  /// # Panics
  ///
  /// Panics when an AudioBuffer is provided via the `ConvolverOptions` with a sample rate
  /// different from the audio context sample rate.
  static Future<ConvolverNode> newInstance(
          {required C context, required ConvolverOptions options}) =>
      RustLib.instance.api
          .webAudioApiNodeConvolverNodeNew(context: context, options: options);

  /// Denotes if the response buffer will be scaled with an equal-power normalization
  Future<bool> normalize() =>
      RustLib.instance.api.webAudioApiNodeConvolverNodeNormalize(
        that: this,
      );

  /// Set or update the impulse response buffer
  ///
  /// # Panics
  ///
  /// Panics when the sample rate of the provided AudioBuffer differs from the audio context
  /// sample rate.
  Future<void> setBuffer({required AudioBuffer buffer}) => RustLib.instance.api
      .webAudioApiNodeConvolverNodeSetBuffer(that: this, buffer: buffer);

  /// Update the `normalize` setting. This will only have an effect when `set_buffer` is called.
  Future<void> setNormalize({required bool value}) => RustLib.instance.api
      .webAudioApiNodeConvolverNodeSetNormalize(that: this, value: value);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<DelayNode>>
@sealed
class DelayNode extends RustOpaque {
  // Not to be used by end users
  DelayNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  DelayNode.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_DelayNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_DelayNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_DelayNodePtr,
  );

  /// A-rate [`AudioParam`] representing the amount of delay (in seconds) to apply.
  Future<AudioParam> delayTime() =>
      RustLib.instance.api.webAudioApiNodeDelayNodeDelayTime(
        that: this,
      );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  /// Create a new DelayNode
  ///
  /// # Panics
  ///
  /// Panics when the max delay value is smaller than zero or langer than three minutes.
  static Future<DelayNode> newInstance(
          {required C context, required DelayOptions options}) =>
      RustLib.instance.api
          .webAudioApiNodeDelayNodeNew(context: context, options: options);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<DynamicsCompressorNode>>
@sealed
class DynamicsCompressorNode extends RustOpaque {
  // Not to be used by end users
  DynamicsCompressorNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  DynamicsCompressorNode.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_DynamicsCompressorNode,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_DynamicsCompressorNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_DynamicsCompressorNodePtr,
  );

  Future<AudioParam> attack() =>
      RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeAttack(
        that: this,
      );

  Future<AudioParam> knee() =>
      RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeKnee(
        that: this,
      );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  static Future<DynamicsCompressorNode> newInstance(
          {required C context, required DynamicsCompressorOptions options}) =>
      RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeNew(
          context: context, options: options);

  Future<AudioParam> ratio() =>
      RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeRatio(
        that: this,
      );

  Future<double> reduction() =>
      RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeReduction(
        that: this,
      );

  Future<AudioParam> release() =>
      RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeRelease(
        that: this,
      );

  Future<AudioParam> threshold() =>
      RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeThreshold(
        that: this,
      );
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<GainNode>>
@sealed
class GainNode extends RustOpaque {
  // Not to be used by end users
  GainNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  GainNode.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_GainNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_GainNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_GainNodePtr,
  );

  Future<AudioParam> gain() => RustLib.instance.api.webAudioApiNodeGainNodeGain(
        that: this,
      );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  static Future<GainNode> newInstance(
          {required C context, required GainOptions options}) =>
      RustLib.instance.api
          .webAudioApiNodeGainNodeNew(context: context, options: options);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<IIRFilterNode>>
@sealed
class IirFilterNode extends RustOpaque {
  // Not to be used by end users
  IirFilterNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  IirFilterNode.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_IirFilterNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_IirFilterNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_IirFilterNodePtr,
  );

  /// Returns the frequency response for the specified frequencies
  ///
  /// # Arguments
  ///
  /// - `frequency_hz` - frequencies for which frequency response of the filter should be calculated
  /// - `mag_response` - magnitude of the frequency response of the filter
  /// - `phase_response` - phase of the frequency response of the filter
  ///
  /// # Panics
  ///
  /// This function will panic if arguments' lengths don't match
  ///
  Future<void> getFrequencyResponse(
          {required F32 frequencyHz,
          required F32 magResponse,
          required F32 phaseResponse}) =>
      RustLib.instance.api.webAudioApiNodeIirFilterNodeGetFrequencyResponse(
          that: this,
          frequencyHz: frequencyHz,
          magResponse: magResponse,
          phaseResponse: phaseResponse);

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  /// Creates an `IirFilterNode`
  ///
  /// # Arguments
  ///
  /// - `context` - Audio context in which the node will live
  /// - `options` - node options
  ///
  /// # Panics
  ///
  /// This function panics if:
  /// - coefs length is 0 and greater than 20
  /// - feedforward coefs are all zeros
  /// - feedback first coef is zero
  ///
  static Future<IirFilterNode> newInstance(
          {required C context, required IIRFilterOptions options}) =>
      RustLib.instance.api
          .webAudioApiNodeIirFilterNodeNew(context: context, options: options);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaElementAudioSourceNode>>
@sealed
class MediaElementAudioSourceNode extends RustOpaque {
  // Not to be used by end users
  MediaElementAudioSourceNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaElementAudioSourceNode.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib.instance.api
        .rust_arc_increment_strong_count_MediaElementAudioSourceNode,
    rustArcDecrementStrongCount: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaElementAudioSourceNode,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaElementAudioSourceNodePtr,
  );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  /// Create a new `MediaElementAudioSourceNode`
  ///
  /// # Panics
  ///
  /// This method will panic when there already exists a source node for the given
  /// `MediaElement`. You can only set up a single source node per element!
  static Future<MediaElementAudioSourceNode> newInstance(
          {required C context,
          required MediaElementAudioSourceOptions options}) =>
      RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeNew(
          context: context, options: options);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaElementAudioSourceOptions>>
@sealed
class MediaElementAudioSourceOptions extends RustOpaque {
  // Not to be used by end users
  MediaElementAudioSourceOptions.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaElementAudioSourceOptions.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib.instance.api
        .rust_arc_increment_strong_count_MediaElementAudioSourceOptions,
    rustArcDecrementStrongCount: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaElementAudioSourceOptions,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaElementAudioSourceOptionsPtr,
  );

  MediaElement get mediaElement => RustLib.instance.api
          .webAudioApiNodeMediaElementAudioSourceOptionsGetMediaElement(
        that: this,
      );

  void set mediaElement(MediaElement mediaElement) => RustLib.instance.api
      .webAudioApiNodeMediaElementAudioSourceOptionsSetMediaElement(
          that: this, mediaElement: mediaElement);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaStream>>
@sealed
class MediaStream extends RustOpaque {
  // Not to be used by end users
  MediaStream.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaStream.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_MediaStream,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_MediaStream,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_MediaStreamPtr,
  );
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaStreamAudioDestinationNode>>
@sealed
class MediaStreamAudioDestinationNode extends RustOpaque {
  // Not to be used by end users
  MediaStreamAudioDestinationNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaStreamAudioDestinationNode.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib.instance.api
        .rust_arc_increment_strong_count_MediaStreamAudioDestinationNode,
    rustArcDecrementStrongCount: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamAudioDestinationNode,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamAudioDestinationNodePtr,
  );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  /// Create a new MediaStreamAudioDestinationNode
  static Future<MediaStreamAudioDestinationNode> newInstance(
          {required C context, required AudioNodeOptions options}) =>
      RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeNew(
          context: context, options: options);

  /// A [`MediaStream`] producing audio buffers with the same number of channels as the node
  /// itself
  Future<MediaStream> stream() =>
      RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeStream(
        that: this,
      );
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaStreamAudioSourceNode>>
@sealed
class MediaStreamAudioSourceNode extends RustOpaque {
  // Not to be used by end users
  MediaStreamAudioSourceNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaStreamAudioSourceNode.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib.instance.api
        .rust_arc_increment_strong_count_MediaStreamAudioSourceNode,
    rustArcDecrementStrongCount: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamAudioSourceNode,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamAudioSourceNodePtr,
  );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  /// Create a new `MediaStreamAudioSourceNode`
  ///
  /// # Panics
  ///
  /// This method will panic when the provided `MediaStream` does not contain any audio tracks.
  static Future<MediaStreamAudioSourceNode> newInstance(
          {required C context,
          required MediaStreamAudioSourceOptions options}) =>
      RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeNew(
          context: context, options: options);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaStreamAudioSourceOptions>>
@sealed
class MediaStreamAudioSourceOptions extends RustOpaque {
  // Not to be used by end users
  MediaStreamAudioSourceOptions.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaStreamAudioSourceOptions.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib.instance.api
        .rust_arc_increment_strong_count_MediaStreamAudioSourceOptions,
    rustArcDecrementStrongCount: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamAudioSourceOptions,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamAudioSourceOptionsPtr,
  );

  MediaStream get mediaStream => RustLib.instance.api
          .webAudioApiNodeMediaStreamAudioSourceOptionsGetMediaStream(
        that: this,
      );

  void set mediaStream(MediaStream mediaStream) => RustLib.instance.api
      .webAudioApiNodeMediaStreamAudioSourceOptionsSetMediaStream(
          that: this, mediaStream: mediaStream);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaStreamTrackAudioSourceNode>>
@sealed
class MediaStreamTrackAudioSourceNode extends RustOpaque {
  // Not to be used by end users
  MediaStreamTrackAudioSourceNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaStreamTrackAudioSourceNode.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib.instance.api
        .rust_arc_increment_strong_count_MediaStreamTrackAudioSourceNode,
    rustArcDecrementStrongCount: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamTrackAudioSourceNode,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamTrackAudioSourceNodePtr,
  );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  static Future<MediaStreamTrackAudioSourceNode> newInstance(
          {required C context,
          required MediaStreamTrackAudioSourceOptions options}) =>
      RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeNew(
          context: context, options: options);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaStreamTrackAudioSourceOptions>>
@sealed
class MediaStreamTrackAudioSourceOptions extends RustOpaque {
  // Not to be used by end users
  MediaStreamTrackAudioSourceOptions.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  MediaStreamTrackAudioSourceOptions.frbInternalSseDecode(
      BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib.instance.api
        .rust_arc_increment_strong_count_MediaStreamTrackAudioSourceOptions,
    rustArcDecrementStrongCount: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamTrackAudioSourceOptions,
    rustArcDecrementStrongCountPtr: RustLib.instance.api
        .rust_arc_decrement_strong_count_MediaStreamTrackAudioSourceOptionsPtr,
  );

  MediaStreamTrack get mediaStreamTrack => RustLib.instance.api
          .webAudioApiNodeMediaStreamTrackAudioSourceOptionsGetMediaStreamTrack(
        that: this,
      );

  void set mediaStreamTrack(MediaStreamTrack mediaStreamTrack) =>
      RustLib.instance.api
          .webAudioApiNodeMediaStreamTrackAudioSourceOptionsSetMediaStreamTrack(
              that: this, mediaStreamTrack: mediaStreamTrack);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<OscillatorNode>>
@sealed
class OscillatorNode extends RustOpaque {
  // Not to be used by end users
  OscillatorNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  OscillatorNode.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_OscillatorNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_OscillatorNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_OscillatorNodePtr,
  );

  /// A-rate [`AudioParam`] that defines a transposition according to the
  /// frequency, expressed in cents.
  ///
  /// see <https://en.wikipedia.org/wiki/Cent_(music)>
  ///
  /// The final frequency is calculated as follow: frequency * 2^(detune/1200)
  Future<AudioParam> detune() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeDetune(
        that: this,
      );

  /// A-rate [`AudioParam`] that defines the fundamental frequency of the
  /// oscillator, expressed in Hz
  ///
  /// The final frequency is calculated as follow: frequency * 2^(detune/1200)
  Future<AudioParam> frequency() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeFrequency(
        that: this,
      );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  /// Returns an `OscillatorNode`
  ///
  /// # Arguments:
  ///
  /// * `context` - The `AudioContext`
  /// * `options` - The OscillatorOptions
  static Future<OscillatorNode> newInstance(
          {required C context, required OscillatorOptions options}) =>
      RustLib.instance.api
          .webAudioApiNodeOscillatorNodeNew(context: context, options: options);

  /// Sets a `PeriodicWave` which describes a waveform to be used by the oscillator.
  ///
  /// Calling this sets the oscillator type to `custom`, once set to `custom`
  /// the oscillator cannot be reverted back to a standard waveform.
  Future<void> setPeriodicWave({required PeriodicWave periodicWave}) =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeSetPeriodicWave(
          that: this, periodicWave: periodicWave);

  /// Set the oscillator type
  ///
  /// # Arguments
  ///
  /// * `type_` - oscillator type (sine, square, triangle, sawtooth)
  ///
  /// # Panics
  ///
  /// if `type_` is `OscillatorType::Custom`
  Future<void> setType({required OscillatorType type}) => RustLib.instance.api
      .webAudioApiNodeOscillatorNodeSetType(that: this, type: type);

  /// Returns the oscillator type
  Future<OscillatorType> type() =>
      RustLib.instance.api.webAudioApiNodeOscillatorNodeType(
        that: this,
      );
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<PannerNode>>
@sealed
class PannerNode extends RustOpaque {
  // Not to be used by end users
  PannerNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  PannerNode.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_PannerNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_PannerNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_PannerNodePtr,
  );

  Future<double> coneInnerAngle() =>
      RustLib.instance.api.webAudioApiNodePannerNodeConeInnerAngle(
        that: this,
      );

  Future<double> coneOuterAngle() =>
      RustLib.instance.api.webAudioApiNodePannerNodeConeOuterAngle(
        that: this,
      );

  Future<double> coneOuterGain() =>
      RustLib.instance.api.webAudioApiNodePannerNodeConeOuterGain(
        that: this,
      );

  Future<DistanceModelType> distanceModel() =>
      RustLib.instance.api.webAudioApiNodePannerNodeDistanceModel(
        that: this,
      );

  Future<double> maxDistance() =>
      RustLib.instance.api.webAudioApiNodePannerNodeMaxDistance(
        that: this,
      );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  /// returns a `PannerNode` instance
  ///
  /// # Arguments
  ///
  /// * `context` - audio context in which the audio node will live.
  /// * `options` - stereo panner options
  ///
  /// # Panics
  ///
  /// Will panic if:
  ///
  /// * `options.channel_config.count` is greater than 2
  /// * `options.channel_config.mode` is `ChannelCountMode::Max`
  ///
  /// Can panic when loading HRIR-sphere
  static Future<PannerNode> newInstance(
          {required C context, required PannerOptions options}) =>
      RustLib.instance.api
          .webAudioApiNodePannerNodeNew(context: context, options: options);

  Future<AudioParam> orientationX() =>
      RustLib.instance.api.webAudioApiNodePannerNodeOrientationX(
        that: this,
      );

  Future<AudioParam> orientationY() =>
      RustLib.instance.api.webAudioApiNodePannerNodeOrientationY(
        that: this,
      );

  Future<AudioParam> orientationZ() =>
      RustLib.instance.api.webAudioApiNodePannerNodeOrientationZ(
        that: this,
      );

  Future<PanningModelType> panningModel() =>
      RustLib.instance.api.webAudioApiNodePannerNodePanningModel(
        that: this,
      );

  Future<AudioParam> positionX() =>
      RustLib.instance.api.webAudioApiNodePannerNodePositionX(
        that: this,
      );

  Future<AudioParam> positionY() =>
      RustLib.instance.api.webAudioApiNodePannerNodePositionY(
        that: this,
      );

  Future<AudioParam> positionZ() =>
      RustLib.instance.api.webAudioApiNodePannerNodePositionZ(
        that: this,
      );

  Future<double> refDistance() =>
      RustLib.instance.api.webAudioApiNodePannerNodeRefDistance(
        that: this,
      );

  Future<double> rolloffFactor() =>
      RustLib.instance.api.webAudioApiNodePannerNodeRolloffFactor(
        that: this,
      );

  Future<void> setConeInnerAngle({required double value}) =>
      RustLib.instance.api
          .webAudioApiNodePannerNodeSetConeInnerAngle(that: this, value: value);

  Future<void> setConeOuterAngle({required double value}) =>
      RustLib.instance.api
          .webAudioApiNodePannerNodeSetConeOuterAngle(that: this, value: value);

  /// Set the coneOuterGain attribute
  ///
  /// # Panics
  ///
  /// Panics if the provided value is not in the range [0, 1]
  Future<void> setConeOuterGain({required double value}) => RustLib.instance.api
      .webAudioApiNodePannerNodeSetConeOuterGain(that: this, value: value);

  Future<void> setDistanceModel({required DistanceModelType value}) =>
      RustLib.instance.api
          .webAudioApiNodePannerNodeSetDistanceModel(that: this, value: value);

  /// Set the maxDistance attribute
  ///
  /// # Panics
  ///
  /// Panics if the provided value is negative.
  Future<void> setMaxDistance({required double value}) => RustLib.instance.api
      .webAudioApiNodePannerNodeSetMaxDistance(that: this, value: value);

  Future<void> setOrientation(
          {required double x, required double y, required double z}) =>
      RustLib.instance.api.webAudioApiNodePannerNodeSetOrientation(
          that: this, x: x, y: y, z: z);

  Future<void> setPanningModel({required PanningModelType value}) =>
      RustLib.instance.api
          .webAudioApiNodePannerNodeSetPanningModel(that: this, value: value);

  Future<void> setPosition(
          {required double x, required double y, required double z}) =>
      RustLib.instance.api
          .webAudioApiNodePannerNodeSetPosition(that: this, x: x, y: y, z: z);

  /// Set the refDistance attribute
  ///
  /// # Panics
  ///
  /// Panics if the provided value is negative.
  Future<void> setRefDistance({required double value}) => RustLib.instance.api
      .webAudioApiNodePannerNodeSetRefDistance(that: this, value: value);

  /// Set the rolloffFactor attribute
  ///
  /// # Panics
  ///
  /// Panics if the provided value is negative.
  Future<void> setRolloffFactor({required double value}) => RustLib.instance.api
      .webAudioApiNodePannerNodeSetRolloffFactor(that: this, value: value);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<ScriptProcessorNode>>
@sealed
class ScriptProcessorNode extends RustOpaque {
  // Not to be used by end users
  ScriptProcessorNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  ScriptProcessorNode.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_ScriptProcessorNode,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_ScriptProcessorNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_ScriptProcessorNodePtr,
  );

  Future<BigInt> bufferSize() =>
      RustLib.instance.api.webAudioApiNodeScriptProcessorNodeBufferSize(
        that: this,
      );

  /// Unset the callback to run when the AudioProcessingEvent is dispatched
  Future<void> clearOnaudioprocess() => RustLib.instance.api
          .webAudioApiNodeScriptProcessorNodeClearOnaudioprocess(
        that: this,
      );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  /// Creates a `ScriptProcessorNode`
  ///
  /// # Arguments
  ///
  /// - `context` - Audio context in which the node will live
  /// - `options` - node options
  ///
  /// # Panics
  ///
  /// This function panics if:
  /// - `buffer_size` is not 256, 512, 1024, 2048, 4096, 8192, or 16384
  /// - the number of input and output channels are both zero
  /// - either of the channel counts exceed [`crate::MAX_CHANNELS`]
  static Future<ScriptProcessorNode> newInstance(
          {required C context, required ScriptProcessorOptions options}) =>
      RustLib.instance.api.webAudioApiNodeScriptProcessorNodeNew(
          context: context, options: options);

  /// Register callback to run when the AudioProcessingEvent is dispatched
  ///
  /// The event handler processes audio from the input (if any) by accessing the audio data from
  /// the inputBuffer attribute. The audio data which is the result of the processing (or the
  /// synthesized data if there are no inputs) is then placed into the outputBuffer.
  ///
  /// The output buffer is shipped back to the render thread when the AudioProcessingEvent goes
  /// out of scope, so be sure not to store it somewhere.
  ///
  /// Only a single event handler is active at any time. Calling this method multiple times will
  /// override the previous event handler.
  Future<void> setOnaudioprocess({required F callback}) =>
      RustLib.instance.api.webAudioApiNodeScriptProcessorNodeSetOnaudioprocess(
          that: this, callback: callback);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<StereoPannerNode>>
@sealed
class StereoPannerNode extends RustOpaque {
  // Not to be used by end users
  StereoPannerNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  StereoPannerNode.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_StereoPannerNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_StereoPannerNode,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_StereoPannerNodePtr,
  );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  /// returns a `StereoPannerNode` instance
  ///
  /// # Arguments
  ///
  /// * `context` - audio context in which the audio node will live.
  /// * `options` - stereo panner options
  ///
  /// # Panics
  ///
  /// Will panic if:
  ///
  /// * `options.channel_config.count` is greater than 2
  /// * `options.channel_config.mode` is `ChannelCountMode::Max`
  ///
  static Future<StereoPannerNode> newInstance(
          {required C context, required StereoPannerOptions options}) =>
      RustLib.instance.api.webAudioApiNodeStereoPannerNodeNew(
          context: context, options: options);

  /// Returns the pan audio parameter
  Future<AudioParam> pan() =>
      RustLib.instance.api.webAudioApiNodeStereoPannerNodePan(
        that: this,
      );
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<WaveShaperNode>>
@sealed
class WaveShaperNode extends RustOpaque {
  // Not to be used by end users
  WaveShaperNode.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  WaveShaperNode.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_WaveShaperNode,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_WaveShaperNode,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_WaveShaperNodePtr,
  );

  /// Returns the distortion curve
  Future<F32?> curve() =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeCurve(
        that: this,
      );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  /// returns a `WaveShaperNode` instance
  ///
  /// # Arguments
  ///
  /// * `context` - audio context in which the audio node will live.
  /// * `options` - waveshaper options
  static Future<WaveShaperNode> newInstance(
          {required C context, required WaveShaperOptions options}) =>
      RustLib.instance.api
          .webAudioApiNodeWaveShaperNodeNew(context: context, options: options);

  /// Returns the `oversample` faactor of this node
  Future<OverSampleType> oversample() =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeOversample(
        that: this,
      );

  /// Set the distortion `curve` of this node
  ///
  /// # Arguments
  ///
  /// * `curve` - the desired distortion `curve`
  ///
  /// # Panics
  ///
  /// Panics if a curve has already been given to the source (though `new` or through
  /// `set_curve`)
  Future<void> setCurve({required List<double> curve}) => RustLib.instance.api
      .webAudioApiNodeWaveShaperNodeSetCurve(that: this, curve: curve);

  /// set the `oversample` factor of this node
  ///
  /// # Arguments
  ///
  /// * `oversample` - the desired `OversampleType` variant
  Future<void> setOversample({required OverSampleType oversample}) =>
      RustLib.instance.api.webAudioApiNodeWaveShaperNodeSetOversample(
          that: this, oversample: oversample);
}

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<[u8]>>
@sealed
class U8 extends RustOpaque {
  // Not to be used by end users
  U8.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  U8.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount:
        RustLib.instance.api.rust_arc_increment_strong_count_U8,
    rustArcDecrementStrongCount:
        RustLib.instance.api.rust_arc_decrement_strong_count_U8,
    rustArcDecrementStrongCountPtr:
        RustLib.instance.api.rust_arc_decrement_strong_count_U8Ptr,
  );
}

/// Options for constructing an [`AnalyserNode`]
class AnalyserOptions {
  final BigInt fftSize;
  final double maxDecibels;
  final double minDecibels;
  final double smoothingTimeConstant;
  final AudioNodeOptions audioNodeOptions;

  const AnalyserOptions({
    required this.fftSize,
    required this.maxDecibels,
    required this.minDecibels,
    required this.smoothingTimeConstant,
    required this.audioNodeOptions,
  });

  @override
  int get hashCode =>
      fftSize.hashCode ^
      maxDecibels.hashCode ^
      minDecibels.hashCode ^
      smoothingTimeConstant.hashCode ^
      audioNodeOptions.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is AnalyserOptions &&
          runtimeType == other.runtimeType &&
          fftSize == other.fftSize &&
          maxDecibels == other.maxDecibels &&
          minDecibels == other.minDecibels &&
          smoothingTimeConstant == other.smoothingTimeConstant &&
          audioNodeOptions == other.audioNodeOptions;
}

/// Options for constructing an [`AudioBufferSourceNode`]
class AudioBufferSourceOptions {
  final AudioBuffer? buffer;
  final double detune;
  final bool loop;
  final double loopStart;
  final double loopEnd;
  final double playbackRate;

  const AudioBufferSourceOptions({
    this.buffer,
    required this.detune,
    required this.loop,
    required this.loopStart,
    required this.loopEnd,
    required this.playbackRate,
  });

  @override
  int get hashCode =>
      buffer.hashCode ^
      detune.hashCode ^
      loop.hashCode ^
      loopStart.hashCode ^
      loopEnd.hashCode ^
      playbackRate.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is AudioBufferSourceOptions &&
          runtimeType == other.runtimeType &&
          buffer == other.buffer &&
          detune == other.detune &&
          loop == other.loop &&
          loopStart == other.loopStart &&
          loopEnd == other.loopEnd &&
          playbackRate == other.playbackRate;
}

/// Options that can be used in constructing all AudioNodes.
class AudioNodeOptions {
  /// Desired number of channels for the [`AudioNode::channel_count`] attribute.
  final BigInt channelCount;

  /// Desired mode for the [`AudioNode::channel_count_mode`] attribute.
  final ChannelCountMode channelCountMode;

  /// Desired mode for the [`AudioNode::channel_interpretation`] attribute.
  final ChannelInterpretation channelInterpretation;

  const AudioNodeOptions({
    required this.channelCount,
    required this.channelCountMode,
    required this.channelInterpretation,
  });

  @override
  int get hashCode =>
      channelCount.hashCode ^
      channelCountMode.hashCode ^
      channelInterpretation.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is AudioNodeOptions &&
          runtimeType == other.runtimeType &&
          channelCount == other.channelCount &&
          channelCountMode == other.channelCountMode &&
          channelInterpretation == other.channelInterpretation;
}

/// Options for constructing a [`BiquadFilterNode`]
class BiquadFilterOptions {
  final double q;
  final double detune;
  final double frequency;
  final double gain;
  final BiquadFilterType type;
  final AudioNodeOptions audioNodeOptions;

  const BiquadFilterOptions({
    required this.q,
    required this.detune,
    required this.frequency,
    required this.gain,
    required this.type,
    required this.audioNodeOptions,
  });

  @override
  int get hashCode =>
      q.hashCode ^
      detune.hashCode ^
      frequency.hashCode ^
      gain.hashCode ^
      type.hashCode ^
      audioNodeOptions.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is BiquadFilterOptions &&
          runtimeType == other.runtimeType &&
          q == other.q &&
          detune == other.detune &&
          frequency == other.frequency &&
          gain == other.gain &&
          type == other.type &&
          audioNodeOptions == other.audioNodeOptions;
}

/// Biquad filter types
enum BiquadFilterType {
  /// Allows frequencies below the cutoff frequency to pass through and
  /// attenuates frequencies above the cutoff. (12dB/oct rolloff)
  lowpass,

  /// Frequencies above the cutoff frequency are passed through, but
  /// frequencies below the cutoff are attenuated. (12dB/oct rolloff)
  highpass,

  /// Allows a range of frequencies to pass through and attenuates the
  /// frequencies below and above this frequency range.
  bandpass,

  /// Allows all frequencies through, except for a set of frequencies.
  notch,

  /// Allows all frequencies through, but changes the phase relationship
  /// between the various frequencies.
  allpass,

  /// Allows all frequencies through, but adds a boost (or attenuation) to
  /// a range of frequencies.
  peaking,

  /// Allows all frequencies through, but adds a boost (or attenuation) to
  /// the lower frequencies.
  lowshelf,

  /// Allows all frequencies through, but adds a boost (or attenuation) to
  /// the higher frequencies.
  highshelf,
  ;
}

/// How channels must be matched between the node's inputs and outputs.
enum ChannelCountMode {
  /// `computedNumberOfChannels` is the maximum of the number of channels of all connections to an
  /// input. In this mode channelCount is ignored.
  max,

  /// `computedNumberOfChannels` is determined as for "max" and then clamped to a maximum value of
  /// the given channelCount.
  clampedMax,

  /// `computedNumberOfChannels` is the exact value as specified by the channelCount.
  explicit,
  ;
}

/// The meaning of the channels, defining how audio up-mixing and down-mixing will happen.
enum ChannelInterpretation {
  speakers,
  discrete,
  ;
}

/// Options for constructing a [`ChannelMergerNode`]
class ChannelMergerOptions {
  final BigInt numberOfInputs;
  final AudioNodeOptions audioNodeOptions;

  const ChannelMergerOptions({
    required this.numberOfInputs,
    required this.audioNodeOptions,
  });

  @override
  int get hashCode => numberOfInputs.hashCode ^ audioNodeOptions.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is ChannelMergerOptions &&
          runtimeType == other.runtimeType &&
          numberOfInputs == other.numberOfInputs &&
          audioNodeOptions == other.audioNodeOptions;
}

/// Options for constructing a [`ChannelSplitterNode`]
class ChannelSplitterOptions {
  final BigInt numberOfOutputs;
  final AudioNodeOptions audioNodeOptions;

  const ChannelSplitterOptions({
    required this.numberOfOutputs,
    required this.audioNodeOptions,
  });

  @override
  int get hashCode => numberOfOutputs.hashCode ^ audioNodeOptions.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is ChannelSplitterOptions &&
          runtimeType == other.runtimeType &&
          numberOfOutputs == other.numberOfOutputs &&
          audioNodeOptions == other.audioNodeOptions;
}

/// Options for constructing an [`ConstantSourceNode`]
class ConstantSourceOptions {
  /// Initial parameter value of the constant signal
  final double offset;

  const ConstantSourceOptions({
    required this.offset,
  });

  @override
  int get hashCode => offset.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is ConstantSourceOptions &&
          runtimeType == other.runtimeType &&
          offset == other.offset;
}

/// `ConvolverNode` options
class ConvolverOptions {
  /// The desired buffer for the ConvolverNode
  final AudioBuffer? buffer;

  /// The opposite of the desired initial value for the normalize attribute
  final bool disableNormalization;

  /// AudioNode options
  final AudioNodeOptions audioNodeOptions;

  const ConvolverOptions({
    this.buffer,
    required this.disableNormalization,
    required this.audioNodeOptions,
  });

  @override
  int get hashCode =>
      buffer.hashCode ^
      disableNormalization.hashCode ^
      audioNodeOptions.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is ConvolverOptions &&
          runtimeType == other.runtimeType &&
          buffer == other.buffer &&
          disableNormalization == other.disableNormalization &&
          audioNodeOptions == other.audioNodeOptions;
}

/// Options for constructing a [`DelayNode`]
class DelayOptions {
  final double maxDelayTime;
  final double delayTime;
  final AudioNodeOptions audioNodeOptions;

  const DelayOptions({
    required this.maxDelayTime,
    required this.delayTime,
    required this.audioNodeOptions,
  });

  @override
  int get hashCode =>
      maxDelayTime.hashCode ^ delayTime.hashCode ^ audioNodeOptions.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is DelayOptions &&
          runtimeType == other.runtimeType &&
          maxDelayTime == other.maxDelayTime &&
          delayTime == other.delayTime &&
          audioNodeOptions == other.audioNodeOptions;
}

/// Algorithm to reduce the volume of an audio source as it moves away from the listener
enum DistanceModelType {
  linear,
  inverse,
  exponential,
  ;
}

/// Options for constructing a [`DynamicsCompressorNode`]
class DynamicsCompressorOptions {
  final double attack;
  final double knee;
  final double ratio;
  final double release;
  final double threshold;
  final AudioNodeOptions audioNodeOptions;

  const DynamicsCompressorOptions({
    required this.attack,
    required this.knee,
    required this.ratio,
    required this.release,
    required this.threshold,
    required this.audioNodeOptions,
  });

  @override
  int get hashCode =>
      attack.hashCode ^
      knee.hashCode ^
      ratio.hashCode ^
      release.hashCode ^
      threshold.hashCode ^
      audioNodeOptions.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is DynamicsCompressorOptions &&
          runtimeType == other.runtimeType &&
          attack == other.attack &&
          knee == other.knee &&
          ratio == other.ratio &&
          release == other.release &&
          threshold == other.threshold &&
          audioNodeOptions == other.audioNodeOptions;
}

/// Options for constructing a [`GainNode`]
class GainOptions {
  final double gain;
  final AudioNodeOptions audioNodeOptions;

  const GainOptions({
    required this.gain,
    required this.audioNodeOptions,
  });

  @override
  int get hashCode => gain.hashCode ^ audioNodeOptions.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is GainOptions &&
          runtimeType == other.runtimeType &&
          gain == other.gain &&
          audioNodeOptions == other.audioNodeOptions;
}

/// Options for constructing a [`IIRFilterNode`]
class IIRFilterOptions {
  /// audio node options
  final AudioNodeOptions audioNodeOptions;

  /// feedforward coefficients
  final Float64List feedforward;

  /// feedback coefficients
  final Float64List feedback;

  const IIRFilterOptions({
    required this.audioNodeOptions,
    required this.feedforward,
    required this.feedback,
  });

  @override
  int get hashCode =>
      audioNodeOptions.hashCode ^ feedforward.hashCode ^ feedback.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is IIRFilterOptions &&
          runtimeType == other.runtimeType &&
          audioNodeOptions == other.audioNodeOptions &&
          feedforward == other.feedforward &&
          feedback == other.feedback;
}

/// Options for constructing an [`OscillatorNode`]
class OscillatorOptions {
  /// The shape of the periodic waveform
  final OscillatorType type;

  /// The frequency of the fundamental frequency.
  final double frequency;

  /// A detuning value (in cents) which will offset the frequency by the given amount.
  final double detune;

  /// Optional custom waveform, if specified (set `type` to "custom")
  final PeriodicWave? periodicWave;

  /// channel config options
  final AudioNodeOptions audioNodeOptions;

  const OscillatorOptions({
    required this.type,
    required this.frequency,
    required this.detune,
    this.periodicWave,
    required this.audioNodeOptions,
  });

  @override
  int get hashCode =>
      type.hashCode ^
      frequency.hashCode ^
      detune.hashCode ^
      periodicWave.hashCode ^
      audioNodeOptions.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is OscillatorOptions &&
          runtimeType == other.runtimeType &&
          type == other.type &&
          frequency == other.frequency &&
          detune == other.detune &&
          periodicWave == other.periodicWave &&
          audioNodeOptions == other.audioNodeOptions;
}

/// Type of the waveform rendered by an `OscillatorNode`
enum OscillatorType {
  /// Sine wave
  sine,

  /// Square wave
  square,

  /// Sawtooth wave
  sawtooth,

  /// Triangle wave
  triangle,

  /// type used when periodic_wave is specified
  custom,
  ;
}

/// enumerates the oversampling rate available for `WaveShaperNode`
enum OverSampleType {
  /// No oversampling is applied
  none,

  /// Oversampled by a factor of 2
  x2,

  /// Oversampled by a factor of 4
  x4,
  ;
}

/// Options for constructing a [`PannerNode`]
class PannerOptions {
  final PanningModelType panningModel;
  final DistanceModelType distanceModel;
  final double positionX;
  final double positionY;
  final double positionZ;
  final double orientationX;
  final double orientationY;
  final double orientationZ;
  final double refDistance;
  final double maxDistance;
  final double rolloffFactor;
  final double coneInnerAngle;
  final double coneOuterAngle;
  final double coneOuterGain;
  final AudioNodeOptions audioNodeOptions;

  const PannerOptions({
    required this.panningModel,
    required this.distanceModel,
    required this.positionX,
    required this.positionY,
    required this.positionZ,
    required this.orientationX,
    required this.orientationY,
    required this.orientationZ,
    required this.refDistance,
    required this.maxDistance,
    required this.rolloffFactor,
    required this.coneInnerAngle,
    required this.coneOuterAngle,
    required this.coneOuterGain,
    required this.audioNodeOptions,
  });

  @override
  int get hashCode =>
      panningModel.hashCode ^
      distanceModel.hashCode ^
      positionX.hashCode ^
      positionY.hashCode ^
      positionZ.hashCode ^
      orientationX.hashCode ^
      orientationY.hashCode ^
      orientationZ.hashCode ^
      refDistance.hashCode ^
      maxDistance.hashCode ^
      rolloffFactor.hashCode ^
      coneInnerAngle.hashCode ^
      coneOuterAngle.hashCode ^
      coneOuterGain.hashCode ^
      audioNodeOptions.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is PannerOptions &&
          runtimeType == other.runtimeType &&
          panningModel == other.panningModel &&
          distanceModel == other.distanceModel &&
          positionX == other.positionX &&
          positionY == other.positionY &&
          positionZ == other.positionZ &&
          orientationX == other.orientationX &&
          orientationY == other.orientationY &&
          orientationZ == other.orientationZ &&
          refDistance == other.refDistance &&
          maxDistance == other.maxDistance &&
          rolloffFactor == other.rolloffFactor &&
          coneInnerAngle == other.coneInnerAngle &&
          coneOuterAngle == other.coneOuterAngle &&
          coneOuterGain == other.coneOuterGain &&
          audioNodeOptions == other.audioNodeOptions;
}

/// Spatialization algorithm used to position the audio in 3D space
enum PanningModelType {
  equalPower,
  hrtf,
  ;
}

/// Options for constructing an [`ScriptProcessorNode`]
class ScriptProcessorOptions {
  final BigInt bufferSize;
  final BigInt numberOfInputChannels;
  final BigInt numberOfOutputChannels;

  const ScriptProcessorOptions({
    required this.bufferSize,
    required this.numberOfInputChannels,
    required this.numberOfOutputChannels,
  });

  @override
  int get hashCode =>
      bufferSize.hashCode ^
      numberOfInputChannels.hashCode ^
      numberOfOutputChannels.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is ScriptProcessorOptions &&
          runtimeType == other.runtimeType &&
          bufferSize == other.bufferSize &&
          numberOfInputChannels == other.numberOfInputChannels &&
          numberOfOutputChannels == other.numberOfOutputChannels;
}

/// Options for constructing a [`StereoPannerOptions`]
class StereoPannerOptions {
  /// initial value for the pan parameter
  final double pan;

  /// audio node options
  final AudioNodeOptions audioNodeOptions;

  const StereoPannerOptions({
    required this.pan,
    required this.audioNodeOptions,
  });

  @override
  int get hashCode => pan.hashCode ^ audioNodeOptions.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is StereoPannerOptions &&
          runtimeType == other.runtimeType &&
          pan == other.pan &&
          audioNodeOptions == other.audioNodeOptions;
}

/// `WaveShaperNode` options
class WaveShaperOptions {
  /// The distortion curve
  final Float32List? curve;

  /// Oversampling rate - default to `None`
  final OverSampleType oversample;

  /// audio node options
  final AudioNodeOptions audioNodeOptions;

  const WaveShaperOptions({
    this.curve,
    required this.oversample,
    required this.audioNodeOptions,
  });

  @override
  int get hashCode =>
      curve.hashCode ^ oversample.hashCode ^ audioNodeOptions.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is WaveShaperOptions &&
          runtimeType == other.runtimeType &&
          curve == other.curve &&
          oversample == other.oversample &&
          audioNodeOptions == other.audioNodeOptions;
}
