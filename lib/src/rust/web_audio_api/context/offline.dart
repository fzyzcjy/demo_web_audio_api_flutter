// This file is automatically generated, so please do not edit it.
// Generated by `flutter_rust_bridge`@ 2.0.0-dev.37.

// ignore_for_file: invalid_use_of_internal_member, unused_import, unnecessary_import

import '../../frb_generated.dart';
import '../buffer.dart';
import '../capacity.dart';
import 'package:flutter_rust_bridge/flutter_rust_bridge_for_generated.dart';

// These functions are ignored because they are not marked as `pub`: `base`, `calculate_suspend_frame`, `fmt`
// These types are ignored because they are not used by any `pub` functions: `OfflineAudioContextRenderer`

// Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<OfflineAudioContext>>
@sealed
class OfflineAudioContext extends RustOpaque {
  // Not to be used by end users
  OfflineAudioContext.frbInternalDcoDecode(List<dynamic> wire)
      : super.frbInternalDcoDecode(wire, _kStaticData);

  // Not to be used by end users
  OfflineAudioContext.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative)
      : super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);

  static final _kStaticData = RustArcStaticData(
    rustArcIncrementStrongCount: RustLib
        .instance.api.rust_arc_increment_strong_count_OfflineAudioContext,
    rustArcDecrementStrongCount: RustLib
        .instance.api.rust_arc_decrement_strong_count_OfflineAudioContext,
    rustArcDecrementStrongCountPtr: RustLib
        .instance.api.rust_arc_decrement_strong_count_OfflineAudioContextPtr,
  );

  /// Unset the callback to run when the rendering has completed
  Future<void> clearOncomplete() => RustLib.instance.api
          .webAudioApiContextOfflineOfflineAudioContextClearOncomplete(
        that: this,
      );

  /// get the length of rendering audio buffer
  Future<BigInt> length() =>
      RustLib.instance.api.webAudioApiContextOfflineOfflineAudioContextLength(
        that: this,
      );

  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.
  /// Creates an `OfflineAudioContext` instance
  ///
  /// # Arguments
  ///
  /// * `channels` - number of output channels to render
  /// * `length` - length of the rendering audio buffer
  /// * `sample_rate` - output sample rate
  static Future<OfflineAudioContext> newInstance(
          {required BigInt numberOfChannels,
          required BigInt length,
          required double sampleRate}) =>
      RustLib.instance.api.webAudioApiContextOfflineOfflineAudioContextNew(
          numberOfChannels: numberOfChannels,
          length: length,
          sampleRate: sampleRate);

  /// Resumes the progression of the OfflineAudioContext's currentTime when it has been suspended
  ///
  /// # Panics
  ///
  /// Panics when the context is closed or rendering has not started
  Future<void> resume() =>
      RustLib.instance.api.webAudioApiContextOfflineOfflineAudioContextResume(
        that: this,
      );

  /// Register callback to run when the rendering has completed
  ///
  /// Only a single event handler is active at any time. Calling this method multiple times will
  /// override the previous event handler.
  Future<void> setOncomplete({required F callback}) => RustLib.instance.api
      .webAudioApiContextOfflineOfflineAudioContextSetOncomplete(
          that: this, callback: callback);

  /// Given the current connections and scheduled changes, starts rendering audio.
  ///
  /// Rendering is purely CPU bound and contains no `await` points, so calling this method will
  /// block the executor until completion or until the context is suspended.
  ///
  /// This method will only adhere to scheduled suspensions via [`Self::suspend`] and will
  /// ignore those provided via [`Self::suspend_sync`].
  ///
  /// # Panics
  ///
  /// Panics if this method is called multiple times.
  Future<AudioBuffer> startRendering() => RustLib.instance.api
          .webAudioApiContextOfflineOfflineAudioContextStartRendering(
        that: this,
      );

  /// Given the current connections and scheduled changes, starts rendering audio.
  ///
  /// This function will block the current thread and returns the rendered `AudioBuffer`
  /// synchronously.
  ///
  /// This method will only adhere to scheduled suspensions via [`Self::suspend_sync`] and
  /// will ignore those provided via [`Self::suspend`].
  ///
  /// # Panics
  ///
  /// Panics if this method is called multiple times
  Future<AudioBuffer> startRenderingSync() => RustLib.instance.api
          .webAudioApiContextOfflineOfflineAudioContextStartRenderingSync(
        that: this,
      );

  /// Schedules a suspension of the time progression in the audio context at the specified time
  /// and returns a promise
  ///
  /// The specified time is quantized and rounded up to the render quantum size.
  ///
  /// # Panics
  ///
  /// Panics if the quantized frame number
  ///
  /// - is negative or
  /// - is less than or equal to the current time or
  /// - is greater than or equal to the total render duration or
  /// - is scheduled by another suspend for the same time
  ///
  /// # Example usage
  ///
  /// ```rust
  /// use futures::{executor, join};
  /// use futures::FutureExt as _;
  /// use std::sync::Arc;
  ///
  /// use web_audio_api::context::BaseAudioContext;
  /// use web_audio_api::context::OfflineAudioContext;
  /// use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};
  ///
  /// let context = Arc::new(OfflineAudioContext::new(1, 512, 44_100.));
  /// let context_clone = Arc::clone(&context);
  ///
  /// let suspend_promise = context.suspend(128. / 44_100.).then(|_| async move {
  ///     let mut src = context_clone.create_constant_source();
  ///     src.connect(&context_clone.destination());
  ///     src.start();
  ///     context_clone.resume().await;
  /// });
  ///
  /// let render_promise = context.start_rendering();
  ///
  /// let buffer = executor::block_on(async move { join!(suspend_promise, render_promise).1 });
  /// assert_eq!(buffer.number_of_channels(), 1);
  /// assert_eq!(buffer.length(), 512);
  /// ```
  Future<void> suspend({required double suspendTime}) =>
      RustLib.instance.api.webAudioApiContextOfflineOfflineAudioContextSuspend(
          that: this, suspendTime: suspendTime);

  /// Schedules a suspension of the time progression in the audio context at the specified time
  /// and runs a callback.
  ///
  /// This is a synchronous version of [`Self::suspend`] that runs the provided callback at
  /// the `suspendTime`. The rendering resumes automatically after the callback has run, so there
  /// is no `resume_sync` method.
  ///
  /// The specified time is quantized and rounded up to the render quantum size.
  ///
  /// # Panics
  ///
  /// Panics if the quantized frame number
  ///
  /// - is negative or
  /// - is less than or equal to the current time or
  /// - is greater than or equal to the total render duration or
  /// - is scheduled by another suspend for the same time
  ///
  /// # Example usage
  ///
  /// ```rust
  /// use web_audio_api::context::BaseAudioContext;
  /// use web_audio_api::context::OfflineAudioContext;
  /// use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};
  ///
  /// let mut context = OfflineAudioContext::new(1, 512, 44_100.);
  ///
  /// context.suspend_sync(128. / 44_100., |context| {
  ///     let mut src = context.create_constant_source();
  ///     src.connect(&context.destination());
  ///     src.start();
  /// });
  ///
  /// let buffer = context.start_rendering_sync();
  /// assert_eq!(buffer.number_of_channels(), 1);
  /// assert_eq!(buffer.length(), 512);
  /// ```
  Future<void> suspendSync(
          {required double suspendTime, required F callback}) =>
      RustLib.instance.api
          .webAudioApiContextOfflineOfflineAudioContextSuspendSync(
              that: this, suspendTime: suspendTime, callback: callback);
}
